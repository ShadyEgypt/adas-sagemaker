{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, cv2, time, json\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from sagemaker.mxnet import MXNetPredictor\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Check if Endpoint creation is successful and create the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Name: yolov8-optimized-images-serverless-endpoint\n",
      "Endpoint Status = InService\n"
     ]
    }
   ],
   "source": [
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "\n",
    "# Restore the endpoint name stored in the 2_DeployEndpoint.ipynb notebook\n",
    "ENDPOINT_NAME = 'yolov8-optimized-images-serverless-endpoint' \n",
    "print(f'Endpoint Name: {ENDPOINT_NAME}')\n",
    "\n",
    "endpoint_created = False\n",
    "while True:\n",
    "    response = sm_client.list_endpoints()\n",
    "    for ep in response['Endpoints']:\n",
    "        print(f\"Endpoint Status = {ep['EndpointStatus']}\")\n",
    "        if ep['EndpointName']==ENDPOINT_NAME and ep['EndpointStatus']=='InService':\n",
    "            endpoint_created = True\n",
    "            break\n",
    "    if endpoint_created:\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = MXNetPredictor(endpoint_name=ENDPOINT_NAME,\n",
    "                             deserializer=JSONDeserializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Run Inference and Generate output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from model with message \"Your invocation timed out while waiting for a response from model container. Review the latency metrics in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/yolov8-optimized-images-serverless-endpoint in account 141178960309 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m orig_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/db6d38a1-4fae2f3d.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m payload \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb64\u001b[39m\u001b[38;5;124m\"\u001b[39m: base64\u001b[38;5;241m.\u001b[39mb64encode(cv2\u001b[38;5;241m.\u001b[39mimencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, orig_image)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtobytes())\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)}]})\n\u001b[0;32m----> 6\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m output_image \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m infer_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/base_predictor.py:212\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes, component_name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_component_name:\n\u001b[1;32m    210\u001b[0m     request_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceComponentName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inference_component_name\n\u001b[0;32m--> 212\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from model with message \"Your invocation timed out while waiting for a response from model container. Review the latency metrics in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/yolov8-optimized-images-serverless-endpoint in account 141178960309 for more information."
     ]
    }
   ],
   "source": [
    "infer_start_time = time.time()\n",
    "\n",
    "orig_image = cv2.imread('./data/db6d38a1-4fae2f3d.jpg')\n",
    "\n",
    "payload = json.dumps({\"image\": [{\"b64\": base64.b64encode(cv2.imencode('.jpg', orig_image)[1].tobytes()).decode('utf-8')}]})\n",
    "result = predictor.predict(payload)\n",
    "\n",
    "output_image = result[\"image\"]\n",
    "\n",
    "infer_end_time = time.time()\n",
    "\n",
    "print(f\"Inference Time = {infer_end_time - infer_start_time:0.4f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = json.loads(payload)\n",
    "b64_image = payload['image'][0][\"b64\"]\n",
    "img_bytes = base64.b64decode(b64_image)\n",
    "jpg_as_np = np.frombuffer(img_bytes, dtype=np.uint8)\n",
    "img = cv2.imdecode(jpg_as_np, flags=cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the base64 string to bytes\n",
    "image_bytes = base64.b64decode(output_image)\n",
    "\n",
    "# Load the image from the bytes using PIL\n",
    "image = Image.open(BytesIO(image_bytes))\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_start_time = time.time()\n",
    "\n",
    "orig_image = cv2.imread('./data/cf3b0008-4cb31ab3.jpg')\n",
    "\n",
    "payload = cv2.imencode('.jpg', orig_image)[1].tobytes()\n",
    "result = predictor.predict(payload)\n",
    "\n",
    "output_image = result[\"image\"]\n",
    "\n",
    "infer_end_time = time.time()\n",
    "\n",
    "print(f\"Inference Time = {infer_end_time - infer_start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the base64 string to bytes\n",
    "image_bytes = base64.b64decode(output_image)\n",
    "\n",
    "# Load the image from the bytes using PIL\n",
    "image = Image.open(BytesIO(image_bytes))\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Cleanup by removing Endpoint, Endpoint Config and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointConfigName': 'yolov8-optimized-images-serverless-endpoint', 'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:141178960309:endpoint-config/yolov8-optimized-images-serverless-endpoint', 'ProductionVariants': [{'VariantName': 'AllTraffic', 'ModelName': 'mxnet-inference-2024-05-23-02-46-29-953', 'InitialVariantWeight': 1.0, 'ServerlessConfig': {'MemorySizeInMB': 3072, 'MaxConcurrency': 1}, 'VolumeSizeInGB': 5}], 'CreationTime': datetime.datetime(2024, 5, 23, 2, 46, 30, 802000, tzinfo=tzlocal()), 'EnableNetworkIsolation': False, 'ResponseMetadata': {'RequestId': 'a40f683a-9560-4d10-81af-6f557ba8767d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'a40f683a-9560-4d10-81af-6f557ba8767d', 'content-type': 'application/x-amz-json-1.1', 'content-length': '468', 'date': 'Thu, 23 May 2024 02:52:16 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = sm_client.describe_endpoint_config(EndpointConfigName=ENDPOINT_NAME)\n",
    "print(response)\n",
    "endpoint_config_name = response['EndpointConfigName']\n",
    "\n",
    "# Delete Endpoint\n",
    "sm_client.delete_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "\n",
    "# Delete Endpoint Configuration\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "# Delete Model\n",
    "for prod_var in response['ProductionVariants']:\n",
    "    model_name = prod_var['ModelName']\n",
    "    sm_client.delete_model(ModelName=model_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
